defaults:
  - dataset: torch
  - dataloader: default
  - _self_

key_mapping:
  inference:
    input:
      text: phones
      initial_state: initial_waveform_mulaw
    output:
      - estimated_waveform_mulaw
      - estimated_melspectrogram
      - estimated_duration
    identifier:
      filename: filename

checkpoint:
  text_to_feat:
  feat_to_wave:
  text_to_wave:

remove_weight_norm: true

output:
  exp_dir: "./exp"
  inference_dir: ${.exp_dir}/inference
  audio:
    sample_rate: ${data.audio.sample_rate}
    key_mapping:
      inference:
        output:
          estimated_waveform_mulaw: "{filename}_estimated.wav"
        reference:
          waveform: "{filename}.wav"
    transforms:
      inference:
        output:
          estimated_waveform_mulaw:
            _target_: torchaudio.transforms.MuLawDecoding
            quantization_channels: ${data.audio.quantization_channels}
        reference:
