defaults:
  - dataset: torch
  - dataloader: default
  - record: vqvae+pretrained_hifigan
  - clip_gradient: vqvae
  - _self_

dataloader:
  train:
    batch_size: 64
  validation:
    batch_size: 64

key_mapping:
  train:
    input:
      input: log_melspectrogram
    output:
      - reconstructed
      - encoded
      - quantized
      - indices
  validation:
    text_to_feat: ${..train}
    transform_middle:
    feat_to_wave:
      input:
        input: reconstructed
      output: estimated_waveform
  inference:
    text_to_feat:
      input:
        quantized: codebook_indices
      output: reconstructed
    transform_middle: ${..validation.transform_middle}
    feat_to_wave: ${..validation.feat_to_wave}

resume:
  continue_from:

pretrained_feat_to_wave:
  path:
  transform_middle:
    _target_: audyn.models.text_to_wave.FastSpeechWaveNetBridge

output:
  exp_dir: "./exp"
  tensorboard_dir: "./tensorboard"
  save_checkpoint:
    iteration:
      every: 20000
      path: ${...exp_dir}/model/vqvae/iteration{iteration}.pth
    epoch:
      every: 200
      path: ${...exp_dir}/model/vqvae/epoch{epoch}.pth
    last:
      path: ${...exp_dir}/model/vqvae/last.pth
    best_epoch:
      path: ${...exp_dir}/model/vqvae/best_epoch.pth

steps:
  epochs: 800
  iterations:
  lr_scheduler:
