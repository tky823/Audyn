defaults:
  - default
  - override dataset: torch
  - override dataloader: default
  - override clip_gradient: clap
  - _self_

dataloader:
  train:
    batch_size: 64
    drop_last: true  # for contrastive learning
  validation:
    batch_size: 64
    drop_last: true  # for contrastive learning

key_mapping:
  train:
    input:
      text: text
      audio: log_melspectrogram
      text_length: text_length
      audio_length: melspectrogram_length
    output:
      - text_embedding
      - audio_embedding
  validation: ${.train}
  inference: ${.train}

ddp_kwargs:
  find_unused_parameters: true

resume:
  continue_from:

output:
  exp_dir: "./exp"
  tensorboard_dir: "./tensorboard"
  save_checkpoint:
    iteration:
      every: 1000
      path: ${...exp_dir}/model/iteration{iteration}.pth
    epoch:
      every: 20
      path: ${...exp_dir}/model/epoch{epoch}.pth
    last:
      path: ${...exp_dir}/model/last.pth
    best_epoch:
      path: ${...exp_dir}/model/best_epoch.pth

steps:
  epochs: 100
  iterations:
  lr_scheduler:
